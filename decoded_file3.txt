A computationally efficient model for multipitch and periodicity analysis is presented in the paper assigned to us. Pitch may be quantified as frequency, but it is not same as frequency. Frequency is a scientific, measurable attribute of a signal. Pitch is a perception of a sound signal by humans, which varies from person to person and cannot be directly measured. The pitch perception models are aimed at simulating human perception.
The unitary pitch analysis model by Meddis and O'Mard and its predecessors by Meddis and Hewitt are some of the recent models of time-domain pitch analysis. This unitary model shows good correspondence to human pitch perception but it has a problem that its algorithm is computationally expensive because the analysis is carried out using a multichannel auditory filterbank. A filterbank is an array of bandpass filters that separates the input signal into multiple components, each one carrying a single frequency sub-band of the original signal. As shown in the figure below, in this model, the is divided into multiple channels using the filterbank and the signal in each channel is half-wave rectified and lowpass filtered. This gives the envelope of the signal in each channel, from which the autocorrelation function (ACF) is computed for each channel. Finally, the ACF of all the channels are added to get a summary autocorrelation function (SACF). SACF is used in the pitch analysis.
The multipitch analysis model is a computational simplification of the unitary pitch analysis model. Some pitch analysis models use DFT based autocorrelation computation, which makes the process computationally efficient. Here, the signal is processed in frequency-domain and the nonlinear compression of DFT magnitude helps enhance the efficiency of pitch analysis.
The proposed model in this paper has only two channels. The signal is first passed through a pre-whitening filter, which removes short-time correlation of the signal. Then the signal is separated into two channels, one with frequencies above 1kHz and the other with frequencies below 1kHz. The high channel signal is half-wave rectified and lowpass filtered. The periodic detections are based on generalized autocorrelation.
The value of k determines the frequency domain compression. This is not directly possible in time-domain algorithms. FFT and IFFT are used to speed the computation.
The last part of this model is enhancing the SACF. The autocorrelation function generates peaks at all integer multiples of the fundamental period. In the plot of SACF, it is difficult to determine which peaks are true pitch peaks. To be more selective, a computationally more straight forward peak pruning technique is used. This technique is explained in the paper. The final resulting function is called the enhanced summary autocorrelation function (ESACF).
The required parameters for each process in this model, comparison of the behaviour for different values of parameters, and the advantages we get by using this model over other models are discussed in the given paper. Finally, the performance of this model is demonstrated with three examples: 1) resolution of harmonic tones with different amplitude; 2) musical chords that are played with real instruments; 3) ESACF representation of a mixture of two vowels with varying pitches.
Computational efficiency allow this model to be used in complex audio signal processing applications like sound source separation, structural representation of audio signals, separation of speech from severe background noise, etc.
A computationally efficient model for multipitch and periodicity analysis of complex audio signals is presented. The model essentially divides the signal into two channels, below and above 1000 Hz, computes a “generalized” autocorrelation of the low-channel signal and of the envelope of the high-channel signal, and sums the autocorrelation functions. The summary autocorrelation function (SACF) is further processed to obtain an enhanced SACF (ESACF). The SACF and ESACF representations are used in observing the periodicities of the signal.
The model performance is demonstrated to be comparable to those of recent time-domain models that apply a multichannel analysis. In contrast to the multichannel models, the proposed pitch analysis model can be run in real time using typical personal computers. The parameters of the model are experimentally tuned for best multipitch discrimination with typical mixtures of complex tones.
The proposed pitch analysis model may be used in complex audio signal processing applications, such as sound source separation, computational auditory scene analysis, and struc- tural representation of audio signals. The performance of the model is demonstrated by pitch analysis examples using sound mixtures which are available for download at http://www.acoustics.hut.fi/~ttolonen/pitchAnalysis/.
Many principles have been proposed for the modeling of human pitch perception and for practical pitch determination of simple audio or speech signals [1]–[3]. For regular signals with harmonic structure, such as clean speech of a single speaker, the problem is solved quite reliably. When the complexity increases further, e.g., when harmonic complexes of sounds or voices are mixed in a single signal channel, the determination of pitches is generally a difficult problem that has not been solved satisfactorily.
Computational algorithms for multipitch identification, for instance, in automatic transcription of polyphonic music, have been around for over 20 years. The first systems had typically substantial limitations on the content, and they were only able to detect up to two simultaneous harmonic tones [4]–[9]. The more recent systems have advanced in performance [10]–[14] allowing more simultaneous tones to be detected with greater accuracy.
The concept of pitch [15] refers to auditory perception and has a complex relationship to physical properties of a signal. Thus, it is natural to distinguish it from the estimation of fundamental frequency and to apply methods that simulate human perception. Many such approaches have been proposed and they generally follow one of two paradigms: place (or frequency) theory and timing (or periodicity) theory. Neither of these in pure form has been proven to show full compatibility with human pitch perception and it is probable that a combination of the two approaches is needed. Recently it has been demonstrated that a peripheral auditory model that uses time-domain processing of periodicity properties shows ability to simulate many known features of pitch perception which are often considered to be more central [16], [17]. Such models are attractive since auditory processes may be simulated with relatively straightforward digital signal processing (DSP) algorithms. Additional features may be readily included using, e.g., frequency domain algorithms if desired.
The unitary pitch analysis model of Meddis and O’Mard [16] and its predecessors by Meddis and Hewitt [17] are among the best known recent models of time-domain pitch analysis.
